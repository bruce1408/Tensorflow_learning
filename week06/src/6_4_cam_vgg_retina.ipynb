{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEAKLY SUPERVISED LOCALIZATION \n",
    "## WITH RETINA DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECIFY WHICH GPU TO USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device_type = \"/gpu:2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    img = scipy.misc.imread(path).astype(np.float)\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.transpose(np.array([img, img, img]), (2, 0, 1))\n",
    "    return img\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(path, img)\n",
    "def print_np(x, s):\n",
    "    print (\"Type of '%s' is %s\" % (s, type(x)))\n",
    "    print (\"Shape of '%s' is %s\" % (s, x.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD CALTECH 101 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "path = cwd + \"/../../retina_dataset/dataset\"\n",
    "valid_exts = [\".jpg\", \".gif\", \".png\", \".jpeg\"]\n",
    "print (\"[%d] CATEGORIES ARE IN \\n %s\" % (len(os.listdir(path)), path))\n",
    "\n",
    "categories = sorted(os.listdir(path))\n",
    "ncategories = len(categories)\n",
    "imgs = []\n",
    "labels = []\n",
    "# LOAD ALL IMAGES \n",
    "for i, category in enumerate(categories):\n",
    "    for f in os.listdir(path + \"/\" + category):\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        if ext.lower() not in valid_exts:\n",
    "            continue\n",
    "        fullpath = os.path.join(path + \"/\" + category, f)\n",
    "        img = scipy.misc.imresize(imread(fullpath), [224, 224, 3])\n",
    "        imgs.append(img) # NORMALIZE IMAGE \n",
    "        label_curr = np.zeros((ncategories))\n",
    "        label_curr[i] = 1\n",
    "        labels.append(label_curr)\n",
    "print (\"Num imgs: %d\" % (len(imgs)))\n",
    "print (\"Num labels: %d\" % (len(labels)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIVIDE THE DATASET INTO TWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndata = len(imgs)\n",
    "ntrain = int(ndata*0.7) # WILL USE 70% FOR TRAINING\n",
    "ntest = ndata-ntrain\n",
    "randidx = np.random.permutation(ndata)\n",
    "trainidx = randidx[:ntrain]\n",
    "testidx = randidx[ntrain+1:]\n",
    "train_imgs = [imgs[idx] for idx in trainidx]\n",
    "train_labels = [labels[idx] for idx in trainidx]\n",
    "test_imgs = [imgs[idx] for idx in testidx]\n",
    "test_labels = [labels[idx] for idx in testidx]\n",
    "# TENSORIZE DATA \n",
    "train_imgs_tensor = np.stack(train_imgs, axis=0)\n",
    "train_labels_tensor = np.stack(train_labels, axis=0)\n",
    "test_imgs_tensor = np.stack(test_imgs, axis=0)\n",
    "test_labels_tensor = np.stack(test_labels, axis=0)\n",
    "print \"Num train_imgs: %d\" % (len(train_imgs))\n",
    "print \"Num test_imgs: %d\" % (len(test_imgs))\n",
    "print_np(train_imgs_tensor, \"train_imgs_tensor\")\n",
    "print_np(train_labels_tensor, \"train_labels_tensor\")\n",
    "print_np(test_imgs_tensor, \"test_imgs_tensor\")\n",
    "print_np(test_labels_tensor, \"test_labels_tensor\")\n",
    "# REMOVE LISTS FROM MEMORY\n",
    "del train_imgs, train_labels, test_imgs, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randidx = np.sort(np.random.randint(ntrain, size=2))-1\n",
    "for i, j in enumerate(randidx):\n",
    "    curr_img = train_imgs_tensor[j, :, :, :]\n",
    "    curr_label = np.argmax(train_labels_tensor[j, :])\n",
    "    plt.figure(i)\n",
    "    plt.imshow(curr_img)\n",
    "    plt.title(\"TRAIN [\" + str(curr_label) + \", \" + categories[curr_label] + \"]\")\n",
    "    plt.draw()\n",
    "randidx = np.sort(np.random.randint(ntest, size=2))-1\n",
    "for i, j in enumerate(randidx):\n",
    "    curr_img = test_imgs_tensor[j, :, :, :]\n",
    "    curr_label = np.argmax(test_labels_tensor[j, :])\n",
    "    plt.figure(i)\n",
    "    plt.imshow(curr_img)\n",
    "    plt.title(\"TEST [\" + str(curr_label) + \", \" + categories[curr_label] + \"]\")\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS FOR USING VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(device_type):\n",
    "    # FUNCTIONS FOR USING VGG19\n",
    "    def conv_layer(input, weights, bias):\n",
    "        conv = tf.nn.conv2d(input, tf.constant(weights), strides=[1, 1, 1, 1], padding='SAME')\n",
    "        return tf.nn.bias_add(conv, bias)\n",
    "    def pool_layer(input):\n",
    "        return tf.nn.max_pool(input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    def preprocess(image, mean_pixel):\n",
    "        return image - mean_pixel\n",
    "    print(\"Functions for VGG ready\")\n",
    "\n",
    "    # Define network\n",
    "    def vggnet(data_path, input_image):\n",
    "        layers = (\n",
    "            'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "            'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "            'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "            'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "            'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "            'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "            'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "            'relu5_3', 'conv5_4', 'relu5_4'\n",
    "        )\n",
    "        data = scipy.io.loadmat(data_path)  # Read .mat file via scipy.io.loadmat\n",
    "        mean = data['normalization'][0][0][0]\n",
    "        mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "        weights = data['layers'][0]\n",
    "        net = {}\n",
    "        current = preprocess(input_image, mean_pixel)\n",
    "        for i, name in enumerate(layers):\n",
    "            kind = name[:4]\n",
    "            if kind == 'conv':\n",
    "                kernels, bias = weights[i][0][0][0][0]\n",
    "                # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "                # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "                kernels = np.transpose(kernels, (1, 0 , 2, 3))\n",
    "                bias = bias.reshape(-1)\n",
    "                current = conv_layer(current, kernels, bias)\n",
    "            elif kind == 'relu':\n",
    "                current = tf.nn.relu(current)\n",
    "            elif kind == 'pool':\n",
    "                current = pool_layer(current)\n",
    "            net[name] = current\n",
    "        assert len(net) == len(layers)\n",
    "        return net, mean_pixel, layers\n",
    "print (\"Network for VGG ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PRETRAINED VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "VGG_PATH = cwd + \"/data/imagenet-vgg-verydeep-19.mat\"\n",
    "img_placeholder = tf.placeholder('float', shape=(None, 224, 224, 3))\n",
    "with tf.device(device_type):\n",
    "    vgg, _, _ = vggnet(VGG_PATH, img_placeholder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE GAP NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "n_output = ncategories\n",
    "y = tf.placeholder('float', [None, n_output])\n",
    "kr = tf.placeholder('float')\n",
    "with tf.device(device_type):\n",
    "    weights = {\n",
    "        'wc': tf.Variable(tf.truncated_normal([3, 3, 512, 512], stddev=0.1)),\n",
    "        'out': tf.Variable(tf.random_normal([512, n_output], stddev=0.1))\n",
    "    }\n",
    "    biases = {\n",
    "        'bc': tf.Variable(tf.random_normal([512], stddev=0.1)),\n",
    "        'out': tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "    }\n",
    "    # NETWORK\n",
    "    \n",
    "    def cam(_x, _W, _b, _kr):\n",
    "        conv = tf.nn.conv2d(_x, _W['wc'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv_relu = tf.nn.relu(tf.nn.bias_add(conv, _b['bc'])) \n",
    "        conv_dr = tf.nn.dropout(conv_relu, _kr)\n",
    "        gap = tf.nn.avg_pool(conv_relu, ksize=[1, 14, 14, 1], strides=[1, 14, 14, 1],\n",
    "                padding='SAME')\n",
    "        gap_dr = tf.nn.dropout(gap, _kr)\n",
    "        gap_vec = tf.reshape(gap_dr, [-1, _W['out'].get_shape().as_list()[0]])\n",
    "        out = tf.add(tf.matmul(gap_vec, _W['out']), _b['out'])\n",
    "        ret = {'gap': gap, 'gap_dr': gap_dr, 'gap_vec': gap_vec, 'out': out}\n",
    "        return ret\n",
    "print (\"NETWORK READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE FUNCTIONS FOR THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(device_type):\n",
    "    pred = cam(vgg['relu5_4'], weights, biases, kr)['out']\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "    optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "    corr = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "    accr = tf.reduce_mean(tf.cast(corr, 'float'))\n",
    "    init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver(max_to_keep=3) \n",
    "print (\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN THE NETWRORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SOME PARAMETERS\n",
    "training_epochs = 200\n",
    "batch_size = 128\n",
    "total_batch = (ntrain // batch_size) + 1\n",
    "disp_step = 20\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "sess.run(init)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    for i in range(total_batch):\n",
    "        randidx = np.random.randint(ntrain, size=batch_size)\n",
    "        batch_x = train_imgs_tensor[randidx, :, :, :]\n",
    "        batch_y = train_labels_tensor[randidx, :]\n",
    "        feeds_iter = {img_placeholder: batch_x, y: batch_y, kr: 0.7}\n",
    "        _, c = sess.run([optm, cost], feed_dict=feeds_iter)\n",
    "        featmap = sess.run(vgg['relu5_4'], feed_dict={img_placeholder: batch_x})\n",
    "        avg_cost += c \n",
    "    avg_cost = avg_cost / total_batch\n",
    "    if epoch % disp_step == 0:\n",
    "        feeds_train = {img_placeholder: batch_x, y: batch_y, kr: 1.}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds_train)\n",
    "        test_idx = np.random.randint(len(test_imgs_tensor), size=128)\n",
    "        test_imgs_temp = test_imgs_tensor[test_idx, :, :, :]\n",
    "        test_labels_temp = test_labels_tensor[test_idx, :]\n",
    "        feeds_test = {img_placeholder: test_imgs_temp, y: test_labels_temp, kr: 1.}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds_test)\n",
    "        print (\"[%d/%d] cost: %.4f train_acc: %.3f test_acc: %.3f\" \n",
    "               % (epoch, training_epochs, avg_cost, train_acc, test_acc))\n",
    "        saver.save(sess, 'nets/cam_vgg_retina.ckpt', global_step=epoch)\n",
    "print (\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restore_flag = 0\n",
    "if restore_flag:\n",
    "    netname = 'nets/cam_vgg_retina.ckpt-10'\n",
    "    saver.restore(sess, netname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK CLASS ACTIVATION MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ntest = test_imgs_tensor.shape[0]\n",
    "randidx = np.random.randint(ntest, size=5)\n",
    "for idx in randidx:\n",
    "    testimg = test_imgs_tensor[idx, :, :, :]\n",
    "    testimg = testimg.reshape((-1,) + testimg.shape)\n",
    "    testlabel = np.argmax(test_labels_tensor[idx, :])\n",
    "\n",
    "    with tf.device(device_type):\n",
    "        vgg, _, _ = vggnet(VGG_PATH, img_placeholder)\n",
    "    cam_testfeat, cam_outval, cam_weights = sess.run([vgg['relu5_4'], pred, weights['out']],\n",
    "                        feed_dict={img_placeholder: testimg, kr: 1.})\n",
    "    predlabel = np.argmax(cam_outval)\n",
    "    predweights = cam_weights[:, predlabel]\n",
    "    camsum = np.zeros((14, 14))\n",
    "    for i in xrange(512): \n",
    "        camsum = camsum + predweights[i] * cam_testfeat[0,:,:,i]\n",
    "    camavg = camsum / 512.\n",
    "\n",
    "    print \"PREDICTED CLASS : %d  (%s)\" % (predlabel, categories[predlabel])\n",
    "    print \"     TRUE CLASS : %d  (%s)\" % (testlabel, categories[testlabel])\n",
    "    # PLOT\n",
    "    fig1 = plt.figure(figsize=(10, 6))\n",
    "    ax1 = fig1.add_subplot(1,2,1)     \n",
    "    ax1.imshow(testimg[0])\n",
    "    ax1.set_title(\"Input Image\")\n",
    "    ax2 = fig1.add_subplot(1,2,2)     \n",
    "    im2 = ax2.imshow(camavg, origin='upper')\n",
    "    ax2.set_title(\"Class Activation Map\")\n",
    "    # plt.colorbar(im2, ax=ax2)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}