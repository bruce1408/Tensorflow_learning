

## TensorFlow在NLP的使用（一）

### 一、Word2vec

word2vec 是 Google 于 2013 年开源的一个用于获取词向量的工具包，作者是 Tomas Mikolov。

它是一个将词表示为一个向量的工具，通过该向量表示，可以用来进行更深入的自然语言处理，比如机器翻译等。

网上资料：

- [自己动手写word2vec 系列文章](https://blog.csdn.net/u014595019/article/details/51884529)
- [word2vec 笔记](https://blog.csdn.net/zhangxb35/article/details/74716245)
- ......

当我们分析图片或者语音的时候，我们通常都是在分析密集的，高纬度的数据集。我们所需的全部信息都储存在原始数据中。

![](http://p35l3ejfq.bkt.clouddn.com/20181012143644.png)

当我们处理自然语言问题的时候，我们通常会做分词，然后给每一个词一个编号，比如猫的编号是 120，狗的编号是 343。比如女生的编号是 1232，女王的编号是 2329。这些编号是没有规律，没有联系的，我们从编号中不能得到词与词之间的相关性。

例如：How are you？

How : 234
Are : 7
you : 987

如果把上面转换为 one-hot 方式：

``` xml
000…1000000…
00000001000…
000…0000010
```

但是你从编号中看不到词与此之间什么相关性。

### 二、Word2vec两种模型

1）连续词袋模型（CBOW）

根据词的上下文词汇来预测目标词汇，例如上下文词汇是“今天早餐吃__”，要预测的目标词汇可能是“面包”。

2）Skip-Gram模型

Skip-Gram模型刚好和CBOW相反，它是通过目标词汇来预测上下文词汇。例如目标词汇是“早餐”，上下文词汇可能是“今天”和“吃面包”。


对于这两种模型的训练，我们可能容易想到，使用 softmax 作为输出层来训练网络。这个方法是可
行的，只不过使用 softmax 作为输出层计算量将会是巨大的。假如我们已知上下文，需要训练模型
预测目标词汇，假设总共有 50000 个词汇，那么每一次训练都需要计算输出层的 50000 个概率值。

所以训练 Word2vec 模型我们通常可以选择使用噪声对比估计（Noise Contrastive Estimation）
。NCE 使用的方法是把上下文 h 对应地正确的目标词汇标记为正样本（D=1），然后再抽取一些错
误的词汇作为负样本（D=0）。然后最大化目标函数的值。


当真实的目标单词被分配到较高的概率，同时噪声单词的概率很低时，目标函数也就达到最大值
了。计算这个函数时，只需要计算挑选出来的k个噪声单词，而不是整个语料库。所以训练速度会
很快。

### 三、Word2vec图形化


### 四、CNN在自然语言处理的应用

说到 CNN 我们首先可能会想到 CNN 在计算机视觉中的应用。近几年 CNN 也开始应用于自然语言处
理，并取得了一些引人注目的成绩。

CNN 应用于 NLP 的任务，处理的往往是以矩阵形式表达的句子或文本。矩阵中的每一行对应于一
个分词元素，一般是一个单词，也可以是一个字符。也就是说每一行都是一个词或者字符的向量
（比如前面说到的 word2vec）。假设我们一共有 10 个词，每个词都用 128 维的向量来表示，那么
我们就可以得到一个 10×128 维的矩阵。这个矩阵就相当于是一副“图像”。


GitHub 上的例子：[cnn-text-classification-tf](https://github.com/dennybritz/cnn-text-classification-tf)

## TensorFlow在语音中的使用（二）

1、声音信号

将 N 个采样点集合成一个观测单位，成为帧。通常 N 的值为 256 或 512，覆盖的时间约为 20-30ms 左右。为了避免两帧之间变化过大，因此会让两相邻帧之间有一段重叠区域。通常语音识别所采用的语音信号的采样频率为 8KHz 或 16KHz。


2、梅尔频率倒谱系数（MFCC）

MFCC 是一种广泛使用的语音特征，在 1980 年由 Davis 和 Mermelstein 研究出来。

3、声谱图

语音被分为很多帧，每帧语音都对应于一个频谱（通过 FFT 计算得到），频谱表示频率与能量的关
系。


4、频谱图

我们先将一帧语音的频谱通过坐标表示出来，如左图。再将图旋转90度，如中间的图。然后把这些幅度映射到一个灰度级表示。


5、spectrogram声谱图


6、共振峰

下面是一个语音的频谱图。峰值就表示语音的主要频率成分，这些峰值成为共振峰。共振峰携带了声音的辨识属性。用它就可以识别不同的声音。


7、包络

我们需要把共振峰提取出来，不仅要提取共振峰的位置，还要提取它们转变的过程，也就是频谱的包络。包络就是一条连接这些共振峰点的平滑曲线。


8、分离包络和频谱的细节


9、Mel频率分析

刚刚我们得到了频谱包络，不过人类听觉感知实验表明，人类的听觉的感知只聚焦在某些特定的区域，而不是整个频谱包络。Mel 频率分析就是基于人类听觉感知实验的。人耳就像一个滤波器组，它只关注某些特定频率的分量，也就是说它只让某些频率的信号通过。并且在低频区域由很多的滤波器，分布比较密集，在高频区域，滤波器比较少，也比较稀疏。

10、Mel频率分析

人的听觉系统是一个特殊的非线性系统，它响应不同频率信号的灵明度是不同的。在语音特征的提取上，人类的听觉系统非常好，它不仅能提取出语义信息，而且能提取出说话人的个人特征。所以语音识别系统中能模拟人类听觉感知处理的特点，就有可能提高语音的识别率。

MFCC 考虑到了人类的听觉特征，将线性频谱映射到基于听觉感知的Mel非线性频谱中。

11、语音处理流程


12、ffmpeg

- `conda install -c conda-forge ffmpeg`
- Windows 安装方式：http://www.bubuko.com/infodetail-786878.html
- Ubuntu 安装方式：http://blog.csdn.net/u012386199/article/details/51188988

